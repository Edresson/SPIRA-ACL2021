{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Report: testes com modelo SPIRAConvV1 e SPIRAConvV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from test import *\n",
    "from utils.generic_utils import load_config, save_config_file\n",
    "from utils.generic_utils import set_init_dict\n",
    "from utils.generic_utils import NoamLR, binary_acc\n",
    "from utils.generic_utils import save_best_checkpoint\n",
    "from utils.tensorboard import TensorboardWriter\n",
    "from models.spiraconv import SpiraConvV1, SpiraConvV2, UTF_SPIRA_ConvLSTM_v1\n",
    "from utils.audio_processor import AudioProcessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import plotly.offline as py\n",
    "import IPython\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import plotly.tools as tls\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import pyloudnorm as pyln\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(val_y, val_preds, unique_labels, show=True, output=None, \n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    cm = confusion_matrix(val_y, val_preds)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 1.4\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class for load a train and test from dataset generate by import_librispeech.py and others\n",
    "    \"\"\"\n",
    "    def __init__(self, c, ap, train=True, max_seq_len=None, test=False):\n",
    "        # set random seed\n",
    "        random.seed(c['seed'])\n",
    "        torch.manual_seed(c['seed'])\n",
    "        torch.cuda.manual_seed(c['seed'])\n",
    "        np.random.seed(c['seed'])\n",
    "        self.c = c\n",
    "        self.ap = ap\n",
    "        self.train = train\n",
    "        self.dataset_csv = c.dataset['train_csv'] if train else c.dataset['eval_csv']\n",
    "        self.dataset_root = c.dataset['train_data_root_path'] if train else c.dataset['eval_data_root_path']\n",
    "        if test:\n",
    "            self.dataset_csv = c.dataset['test_csv']\n",
    "            self.dataset_root = c.dataset['test_data_root_path']\n",
    "        self.noise_csv = c.dataset['noise_csv'] \n",
    "        self.noise_root = c.dataset['noise_data_root_path']\n",
    "        assert os.path.isfile(self.dataset_csv),\"Test or Train CSV file don't exists! Fix it in config.json\"\n",
    "        assert os.path.isfile(self.noise_csv),\"Noise CSV file don't exists! Fix it in config.json\"\n",
    "        \n",
    "        # read csvs\n",
    "        self.dataset_list = pd.read_csv(self.dataset_csv, sep=',').values\n",
    "        self.noise_list = pd.read_csv(self.noise_csv, sep=',').values\n",
    "        # noise config\n",
    "        self.num_noise_files = len(self.noise_list)-1\n",
    "        self.control_class = c.dataset['control_class']\n",
    "        self.patient_class = c.dataset['patient_class']\n",
    "\n",
    "        # get max seq lenght for padding \n",
    "        if self.c.dataset['padding_with_max_lenght'] and train and not self.c.dataset['max_seq_len']:\n",
    "            self.max_seq_len = 0\n",
    "            for idx in range(len(self.dataset_list)):\n",
    "                wav = self.ap.load_wav(os.path.join(self.dataset_root, self.dataset_list[idx][0]))\n",
    "                # calculate time step dim using hop lenght\n",
    "                seq_len = int((wav.shape[1]/c.audio['hop_length'])+1)\n",
    "                if seq_len > self.max_seq_len:\n",
    "                    self.max_seq_len = seq_len\n",
    "            print(\"The Max Time dim Lenght is: \", self.max_seq_len)\n",
    "        else: # for eval set max_seq_len in train mode\n",
    "            if self.c.dataset['max_seq_len']:\n",
    "                self.max_seq_len = self.c.dataset['max_seq_len']\n",
    "            else:\n",
    "                self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_max_seq_lenght(self):\n",
    "        return self.max_seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.dataset_root, self.dataset_list[idx][0])\n",
    "        wav = self.ap.load_wav(path)\n",
    "        class_name = self.dataset_list[idx][1]\n",
    "\n",
    "        # its assume that noise file is biggest than wav file !!\n",
    "        if self.c.data_aumentation['insert_noise']:\n",
    "            if self.control_class == class_name: # if sample is a control sample\n",
    "                #print('antes',wav.shape)\n",
    "                # torchaudio.save('antes_control.wav', wav, self.ap.sample_rate)\n",
    "                for _ in range(self.c.data_aumentation['num_noise_control']):\n",
    "                    # choise random noise file\n",
    "                    noise_wav = self.ap.load_wav(os.path.join(self.noise_root, self.noise_list[random.randint(0, self.num_noise_files)][0]))\n",
    "                    noise_wav_len = noise_wav.shape[1]\n",
    "                    wav_len = wav.shape[1]\n",
    "                    noise_start_slice = random.randint(0,noise_wav_len-(wav_len+1))\n",
    "                    # sum two diferents noise\n",
    "                    noise_wav = noise_wav[:,noise_start_slice:noise_start_slice+wav_len]\n",
    "                    # get random max amp for noise\n",
    "                    max_amp = random.uniform(self.c.data_aumentation['noise_min_amp'], self.c.data_aumentation['noise_max_amp'])\n",
    "                    reduct_factor = max_amp/float(noise_wav.max().numpy())\n",
    "                    noise_wav = noise_wav*reduct_factor\n",
    "                    wav = wav + noise_wav\n",
    "                #torchaudio.save('depois_controle.wav', wav, self.ap.sample_rate)\n",
    "                \n",
    "            elif self.patient_class == class_name: # if sample is a patient sample\n",
    "                for _ in range(self.c.data_aumentation['num_noise_patient']):\n",
    "                    \n",
    "                    # torchaudio.save('antes_patiente.wav', wav, self.ap.sample_rate)\n",
    "                    # choise random noise file\n",
    "                    noise_wav = self.ap.load_wav(os.path.join(self.noise_root, self.noise_list[random.randint(0, self.num_noise_files)][0]))\n",
    "                    noise_wav_len = noise_wav.shape[1]\n",
    "                    wav_len = wav.shape[1]\n",
    "                    noise_start_slice = random.randint(0,noise_wav_len-(wav_len+1))\n",
    "                    # sum two diferents noise\n",
    "                    noise_wav = noise_wav[:,noise_start_slice:noise_start_slice+wav_len]\n",
    "                    # get random max amp for noise\n",
    "                    max_amp = random.uniform(self.c.data_aumentation['noise_min_amp'], self.c.data_aumentation['noise_max_amp'])\n",
    "                    reduct_factor = max_amp/float(noise_wav.max().numpy())\n",
    "                    noise_wav = noise_wav*reduct_factor\n",
    "                    wav = wav + noise_wav\n",
    "                \n",
    "                #torchaudio.save('depois_patient.wav', wav, self.ap.sample_rate)\n",
    "                \n",
    "        # feature shape (Batch_size, n_features, timestamp)\n",
    "        feature = self.ap.get_feature_from_audio(wav)\n",
    "        # transpose for (Batch_size, timestamp, n_features)\n",
    "        feature = feature.transpose(1,2)\n",
    "        # remove batch dim = (timestamp, n_features)\n",
    "        feature = feature.reshape(feature.shape[1:])\n",
    "        if not self.c.dataset['padding_with_max_lenght']:\n",
    "            # generate tensor with zeros for each timestep\n",
    "            target = torch.zeros(feature.shape[0],1)+class_name\n",
    "        else:\n",
    "            # padding for max sequence \n",
    "            zeros = torch.zeros(self.max_seq_len - feature.size(0),feature.size(1))\n",
    "            # append zeros before features\n",
    "            feature = torch.cat([feature, zeros], 0)\n",
    "            target = torch.FloatTensor([class_name])\n",
    "        return feature, target, path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def own_collate_fn(batch):\n",
    "    features = []\n",
    "    targets = []\n",
    "    paths = []\n",
    "    for feature, target, path in batch:\n",
    "        paths.append(path)\n",
    "        features.append(feature)\n",
    "        #print(target.shape)\n",
    "        targets.append(target)\n",
    "    # padding with zeros timestamp dim\n",
    "    features = pad_sequence(features, batch_first=True, padding_value=0)\n",
    "\n",
    "    # its padding with zeros but mybe its a problem because \n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    # list to tensor\n",
    "    #targets = stack(targets, dim=0)\n",
    "    #features = stack(features, dim=0)\n",
    "    return features, targets, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def TestDataloader(c, ap, max_seq_len=None):\n",
    "    return DataLoader(dataset=Dataset(c, ap, train=False, test=True, max_seq_len=max_seq_len),\n",
    "                          collate_fn=own_collate_fn, batch_size=c.test_config['batch_size'], \n",
    "                          shuffle=False, num_workers=c.test_config['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test(criterion, ap, model, c, testloader, step,  cuda, confusion_matrix=False):\n",
    "    padding_with_max_lenght = c.dataset['padding_with_max_lenght']\n",
    "    losses = []\n",
    "    accs = []\n",
    "    model.zero_grad()\n",
    "    model.eval()\n",
    "    loss = 0 \n",
    "    acc = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    paths = []\n",
    "    with torch.no_grad():\n",
    "        for feature, target, path in testloader:       \n",
    "            #try:\n",
    "            if cuda:\n",
    "                feature = feature.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            output = model(feature).float()\n",
    "            paths.append(path)\n",
    "            # output = torch.round(output * 10**4) / (10**4)\n",
    "\n",
    "            # Calculate loss\n",
    "            if not padding_with_max_lenght:\n",
    "                target = target[:, :output.shape[1],:target.shape[2]]\n",
    "            loss += criterion(output, target).item()\n",
    "\n",
    "            # calculate binnary accuracy\n",
    "            y_pred_tag = torch.round(output)\n",
    "            acc += (y_pred_tag == target).float().sum().item()\n",
    "            preds += y_pred_tag.reshape(-1).int().cpu().numpy().tolist()\n",
    "            targets += target.reshape(-1).int().cpu().numpy().tolist()\n",
    "        if confusion_matrix:\n",
    "            print(\"======== Confusion Matrix ==========\")\n",
    "            y_target = pd.Series(targets, name='Target')\n",
    "            y_pred = pd.Series(preds, name='Predicted')\n",
    "            df_confusion = pd.crosstab(y_target, y_pred, rownames=['Target'], colnames=['Predicted'], margins=True)\n",
    "            print(df_confusion)\n",
    "            \n",
    "        mean_acc = acc / len(testloader.dataset)\n",
    "        mean_loss = loss / len(testloader.dataset)\n",
    "    print(\"Test\\n Loss:\", mean_loss, \"Acurracy: \", mean_acc)\n",
    "    return mean_acc, df_confusion, preds, targets, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def run_test(config_path, cuda=True, *args, **kwargs):\n",
    "    c = load_config(config_path)\n",
    "    ap = AudioProcessor(**c.audio)\n",
    "\n",
    "    if not no_insert_noise:\n",
    "        c.data_aumentation['insert_noise'] = True\n",
    "    else:\n",
    "        c.data_aumentation['insert_noise'] = False\n",
    "    print(\"Insert noise ?\", c.data_aumentation['insert_noise'])\n",
    "\n",
    "    c.dataset['test_csv'] = test_csv\n",
    "    c.dataset['test_data_root_path'] = test_root_dir\n",
    "    c.test_config['batch_size'] = batch_size\n",
    "    c.test_config['num_workers'] = num_workers\n",
    "    max_seq_len = c.dataset['max_seq_len'] \n",
    "\n",
    "    testloader = TestDataloader(c, ap, max_seq_len=max_seq_len)\n",
    "    \n",
    "  # define loss function\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "\n",
    "    padding_with_max_lenght = c.dataset['padding_with_max_lenght']\n",
    "    if 'v1' in checkpoint_path:\n",
    "        model = SpiraConvV1(c)\n",
    "    elif 'v2' in checkpoint_path:\n",
    "        model = SpiraConvV2(c)\n",
    "\n",
    "    if c.train_config['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=c.train_config['learning_rate'])\n",
    "    else:\n",
    "        raise Exception(\"The %s  not is a optimizer supported\" % c.train['optimizer'])\n",
    "\n",
    "    step = 0\n",
    "    if checkpoint_path is not None:\n",
    "        print(\"Loading checkpoint: %s\" % checkpoint_path)\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            print(\"Model Sucessful Load !\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"You need pass a valid checkpoint, may be you need check your config.json because de the of this checkpoint cause the error: \"+ e)       \n",
    "        step = checkpoint['step']\n",
    "    else:\n",
    "        raise ValueError(\"You need pass a checkpoint_path\")   \n",
    "\n",
    "    # convert model from cuda\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    model.train(False)\n",
    "    return test(criterion, ap, model, c, testloader, step, cuda=cuda, confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                            fs=sample_rate,\n",
    "                                            window='hann',\n",
    "                                            nperseg=nperseg,\n",
    "                                            noverlap=noverlap,\n",
    "                                            detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def mfcc_specgram(audio, sample_rate, nframes, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "#     pad_width = max_pad_len - mfccs.shape[1]\n",
    "#     mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_loudness(sr, b):\n",
    "    meter = pyln.Meter(sr) # create BS.1770 meter\n",
    "    loudness = meter.integrated_loudness(b) # measure loudness\n",
    "    \n",
    "def plot_waveform(name, b):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax2 = fig.add_subplot(211)\n",
    "    ax2.plot(b)\n",
    "    ax2.set_title('Waveform of ' + name)\n",
    "    ax2.set_ylabel('Amplitude')\n",
    "    ax2.set_xlabel('Seconds')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def plot_spectrogram(name, sr, b):\n",
    "    freqs, times, spectrogram = log_specgram(b, sr)\n",
    "    print(spectrogram.shape, freqs.shape, times.shape)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax2 = fig.add_subplot(211)\n",
    "    ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "    ax2.set_yticks(freqs[::40])\n",
    "    ax2.set_xticks(times[::400])\n",
    "    ax2.set_title('Spectrogram of ' + name)\n",
    "    ax2.set_ylabel('Freqs in Hz')\n",
    "    ax2.set_xlabel('Seconds')\n",
    "    plt.show()\n",
    "    plt.close()  \n",
    "    \n",
    "def plot_mfcc(name, sr, b, nframes):\n",
    "    spectrogram = mfcc_specgram(b, sr, nframes, n_mfcc=40)\n",
    "    fig = plt.figure(figsize=(8, 3))\n",
    "    librosa.display.specshow(spectrogram, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def load_wav_file(path):\n",
    "    b, sr = sf.read(path) \n",
    "    return sr, b\n",
    "\n",
    "def show_sample(path, target, pred, show_mfcc=True, show_spec=True, only_if_incorrect=True):\n",
    "    if target == pred and only_if_incorrect:\n",
    "        return\n",
    "#     sr, b = load_wav_file(path)\n",
    "    print(\"target:\", \"CONTROLE\" if target==0 else \"PACIENTE\")\n",
    "    print(\"pred:\", \"CONTROLE\" if pred==0 else \"PACIENTE\")\n",
    "#     print('Playing', path)\n",
    "#     IPython.display.display(ipd.Audio(path))\n",
    "#     plot_waveform(path, b)\n",
    "#     if show_spec:\n",
    "#         plot_spectrogram(path, sr, b)\n",
    "#     if show_mfcc:\n",
    "#         plot_mfcc(path, sr, b, len(b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!ls checkpoints/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_faixa_etaria(idade, intervalo=10):\n",
    "    for i in range(0, 100, 10):\n",
    "        if i <= idade <= i+intervalo:\n",
    "            return f'Entre {i} e {i+intervalo}'\n",
    "\n",
    "\n",
    "def show_info_errors(csv, paths_errors):\n",
    "    pass\n",
    "#     data = pd.read_csv(csv)\n",
    "#     data = data[~data['file_path'].isin(paths_errors)]\n",
    "    \n",
    "#     total = len(data['sexo'])\n",
    "#     sizes = [len(data[data['sexo']=='F'])/total, len(data[data['sexo']=='M'])/total]\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.pie(sizes, labels=[\"Feminino\", \"Masculino\"], autopct='%1.1f%%',\n",
    "#             shadow=True, startangle=90)\n",
    "#     ax1.axis('equal')\n",
    "#     plt.title(\"Gênero (erros)\")\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    \n",
    "    \n",
    "#     controle = data[data['class']==0]\n",
    "#     total = len(controle['sexo'])\n",
    "#     sizes = [len(controle[controle['sexo']=='F'])/total, len(controle[controle['sexo']=='M'])/total]\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.pie(sizes, labels=[\"Feminino\", \"Masculino\"], autopct='%1.1f%%',\n",
    "#             shadow=True, startangle=90)\n",
    "#     ax1.axis('equal')\n",
    "#     plt.title(\"Gênero no controle (erros)\")\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    \n",
    "    \n",
    "#     pacientes = data[data['class']==1]\n",
    "#     total = len(pacientes['sexo'])\n",
    "#     sizes = [len(pacientes[pacientes['sexo']=='F'])/total, len(pacientes[pacientes['sexo']=='M'])/total]\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.pie(sizes, labels=[\"Feminino\", \"Masculino\"], autopct='%1.1f%%',\n",
    "#             shadow=True, startangle=90)\n",
    "#     ax1.axis('equal')\n",
    "#     plt.title(\"Gênero em pacientes (erros)\")\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    \n",
    "#     plt.figure(figsize=(8,3))\n",
    "#     evals = data['faixa_etaria'] = data['idade'].apply(get_faixa_etaria).value_counts()\n",
    "#     sns.barplot(evals.index, evals.values)\n",
    "#     plt.xticks(rotation='vertical')\n",
    "#     plt.xlabel('Idade')\n",
    "#     plt.ylabel('Frequência')\n",
    "#     plt.title(\"Faixa etária (erros)\")\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SPIRAConvV1-MEL_SPEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SPIRAConvV1-MEL_MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_75/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_75/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=False, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SPIRAConvV2-MEL_MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v2_78/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v2_78/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v2_78/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v2_78/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v2_78/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v2_78/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v2_78/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v2_78/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=True)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SPIRAConvV1-MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_73/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_73/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=False)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_eval.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_73/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_73/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=False)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_73/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_73/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=False)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test - With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_csv = \"../SPIRA_Dataset_V1/metadata_test.csv\"\n",
    "test_root_dir = \"../SPIRA_Dataset_V1/\"\n",
    "checkpoint_path = \"checkpoints/spiraconv_v1_73/best_checkpoint.pt\"\n",
    "config = \"checkpoints/spiraconv_v1_73/config.json\"\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "no_insert_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mean_acc, df_confusion, preds, targets, paths = run_test(config,\n",
    "                                                         test_csv=test_csv, \n",
    "                                                         test_root_dir=test_root_dir,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         num_workers=num_workers,\n",
    "                                                         no_insert_noise=no_insert_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(targets, preds, unique_labels=[\"CONTROLE\", \"PACIENTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "paths_errors = []\n",
    "for path, target, pred in zip(paths, targets, preds):\n",
    "    show_sample(path[0], target, pred, show_mfcc=True, show_spec=False)\n",
    "    if target!=pred:\n",
    "        paths_errors.append(path)\n",
    "show_info_errors(test_csv, paths_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
